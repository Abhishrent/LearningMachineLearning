{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee47a062",
   "metadata": {},
   "source": [
    "## Types of machine Learning\n",
    "- Supervised\n",
    "- Unsupervised\n",
    "- Recommender systems\n",
    "- Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1f848b",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "A bunch of input to output mappings are provided and the model is trained on them so that when the output is removed at one point, the machine can still predict the possible output in a reasonably accurate manner.  \n",
    "This should work even for a brand new never-seen-before input.\n",
    "\n",
    "Input(x)|Output(y)|Application\n",
    "-|-|-|\n",
    "email|spam(0/1)|spam filtering|\n",
    "audio|text transcripts|speech recognition|\n",
    "English|Spanish|machine translation|\n",
    "ads, user information|click(0/1)|online advertising|\n",
    "image, sensor info|position of other cars|self-drivingc car|\n",
    "image of a phone|defect(0/1)|visual inspection|\n",
    "\n",
    "**Some examples of Supervised Learning**  \n",
    "Regression  \n",
    "Classification  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5abe023",
   "metadata": {},
   "source": [
    "### Regression and Classification Application\n",
    "Regression|Classification|\n",
    "----------|--------------|\n",
    "Predict a number|Predict categories| \n",
    "from infinitely many possible outputs|from small number of possible outputs|\n",
    "example: predicting housing prices based on land size| example: predicting whether a tumor is malignant or benign|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28449cf3",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "Data comes with only inputs x, but no output labels y.\n",
    "\n",
    "There is no supervision on what to look for, for example the output. The model recognises patterns or structures in the data on it's own.\n",
    "\n",
    "For example: Google News uses the **clustering algorithm** to group related news articles together every day. \n",
    "\n",
    "**Some other examples of Unsupervised Learning Algorithms**\n",
    "Algorithm|Use case\n",
    "-|-\n",
    "Clustering|Group similar data points together\n",
    "Anomaly Detection| Detect unusual data points (for example: Financial system fraud detection, the unusual data point being an unusual transaction)\n",
    "Dimensionality Reduction|Compress data using fewer numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d267f295",
   "metadata": {},
   "source": [
    "## Linear Regression Model\n",
    "Fitting a straight line to your data  \n",
    "\n",
    "It predicts numbers as the output. Any supervised learning model that predicts numbers is addressing what's called a regression problem.\n",
    "There are other models for addressing regression problems however.\n",
    "\n",
    "In contrast to a regression model we have a classification model.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe2d09a",
   "metadata": {},
   "source": [
    "## Classification Model\n",
    "Predicts catgories or discrete categories (is a certain picture of a cat or not?)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d74a7c",
   "metadata": {},
   "source": [
    "## Some common terminologies in ML\n",
    "\n",
    "Terminology|What it means|\n",
    "-|-|\n",
    "Training set|Data used to train the model, consists of **features** and **targets**\n",
    "input variable/input feature/feature|Input to a model\n",
    "output variable/ target variable| Output that a model gives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda1453d",
   "metadata": {},
   "source": [
    "## Notations\n",
    "x = **input variable** or **feature** or **input feature**  \n",
    "y = **output variable** or **output target** or **target**    \n",
    "m = total number of training examples  \n",
    "(x, y) = single training example  \n",
    "(x<sup>i</sup>, y<sup>i</sup>) = i<sup>th</sup> training example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb330365",
   "metadata": {},
   "source": [
    "### Housing price example\n",
    "s.n|size in ft (x)|price in $1000 (y)\n",
    "-|-|-|\n",
    "1|2122|400\n",
    "2|1231|234\n",
    "3|5433|315\n",
    "4|2132|190\n",
    "...|...|...\n",
    "47|3210|870\n",
    "\n",
    "Here,  \n",
    "m = 47  \n",
    "(x<sup>3</sup>, y<sup>3</sup>) = (5433, 315)\n",
    "\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    L[Learning Model]\n",
    "    T[Training Set]\n",
    "    F[Function]\n",
    "    T --> L --> F\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "\tX(x)\n",
    "\t-->F[Function]\n",
    "\t-->Y(Expected output of y)\n",
    "```\n",
    "\n",
    "If x is the feature and y is the target,\n",
    "The function takes in an input x and produces an estimate or prediction for y, represented as $\\hat{y}$  \n",
    "\n",
    " **Note: The output produced by the function is not the target (y) but an estimation or prediction of the target that may or may not equal to the target.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a9f6a",
   "metadata": {},
   "source": [
    "## How to represent f?\n",
    " A key concern when we design a learning algorithm is how we are we going to represent the function f.    \n",
    "\n",
    " That is, what is the mathematical formula that we are going to use to compute f?  \n",
    "\n",
    " Consider f is a straight line, then f can be represented as,      \n",
    "\n",
    "$$f_{w,b}(x) = wx + b$$\n",
    "\n",
    " or, $$f(x) = wx + b$$ simply.\n",
    "\n",
    " where, f is a function that takes x as input and outputs some value of a prediction $\\hat{y}$, depending on the values of the parameters w and b.\n",
    "\n",
    " In ML, the parameters of a model are the variables that you can adjust during training in order to improve the model. Parameters are also referred to as coefficients or weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18081067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = 2 * x + 5 + np.random.normal(0, 1, 100)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot scatter points\n",
    "plt.scatter(x, y, marker='x', color='blue', label='Data points')\n",
    "\n",
    "# Calculate and plot regression line\n",
    "coefficients = np.polyfit(x, y, 1)\n",
    "regression_line = np.poly1d(coefficients)\n",
    "plt.plot(x, regression_line(x), color='red', label='Regression line')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Linear Regression Line', fontsize=14)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "\n",
    "# Set axis limits\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(4, 26)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca11f4",
   "metadata": {},
   "source": [
    "The red line represents the function $f(x)$ that outputs an **estimation of $y$** (i.e $\\hat{y}$).  \n",
    "\n",
    "$$f_{w,b}(x^{(i)}) = wx^{(i)} + b = \\hat{y}^{(i)}$$ \n",
    "\n",
    "**We may also fit a non linear function such as a curve or a parbola as per need and the representation of the function changes accordingly.**  \n",
    "\n",
    "Univariate linear regression = Lnear model with one input variable  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e1767",
   "metadata": {},
   "source": [
    "## Cost Function\n",
    "Tells us how well the model is doing.  It measures how well the values of the parameters fit the training data.  \n",
    "\n",
    "**What do w and b do?**  \n",
    "w is the slope and b is the y-intercept. They determine the function f.  \n",
    "\n",
    "**The goal** is to find the values for w and b so that \n",
    "$$\\hat{y}^{(i)} \\text{ is close to } y^{(i)} \\text{ for all } (x^{(i)},y^{(i)})$$\n",
    "\n",
    "\n",
    "**The cost function takes the prediction $\\hat{y}$ and compares it to the target y by taking $\\hat{y}$ - y, called error, raised to it's square for different training examples i in the training set and sums it up to measure the error across the entire training set from i = 1 all the way upto m where m is the number of training examples.** \n",
    "\n",
    "$$\\sum_{i=1}^m (\\hat{y}^{(i)} - y^{(i)})^2$$\n",
    "\n",
    "At this stage the cost function will calculate a bigger number as your training examples increase.  \n",
    "\n",
    "We compute the average squared error instead of the total squared error in order to prevent this by dividing it by m. By convention we also multiply the m by 2 to make the calculations more neat. The cost function works however though.  \n",
    "\n",
    "\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum_{i=1}^m (\\hat{y}^{(i)} - y^{(i)})^2$$\n",
    "\n",
    "In ML we use different cost functions for different applications. This squared error cost function is by far the most used one for linear regression.\n",
    "\n",
    "### In conclusion\n",
    "We have,  \n",
    "\n",
    "**Squared Error Cost Function:**  \n",
    "$$J(w,b) = \\frac{1}{2m} \\sum_{i=1}^m (\\hat{y}^{(i)} - y^{(i)})^2$$  \n",
    "\n",
    "Can be rewritten as:  \n",
    "$$J(w,b) = \\frac{1}{2m} \\sum_{i=1}^m (f_{w,b}(x^{(i)}) - y^{(i)})^2$$  \n",
    "\n",
    "**Note: $\\hat{y}$ (the prediction of y) lies in the fitted line while the actual y may not.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fdd27a",
   "metadata": {},
   "source": [
    "## The intuition behind the cost function\n",
    "\n",
    "The goal of linear regression is to find the values for parameters that result in the smallest possible value of the cost function J.  \n",
    "\n",
    "We've got the model: $$f_{w,b}(x) = wx + b$$\n",
    "\n",
    "And the corresponding cost function:\n",
    "\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum_{i=1}^m (f_{w,b}(x^{(i)}) - y^{(i)})^2$$  \n",
    "\n",
    "The goal is to make $$J(w,b)$$ as small as possible, mathematically denoted as:\n",
    "\n",
    "$$minimize\\ J(w,b) \\\\w,b$$\n",
    "\n",
    "But in order better visualize things, let us simplify the model by getting rid of the paramter b altogether so that we only have to deal with a single parameter w.  \n",
    "\n",
    "**The simplification gives us the following:**\n",
    "\n",
    "The model: \n",
    "\n",
    "$$f_w(x) = wx$$\n",
    "\n",
    "The corresponding cost function: \n",
    "$$J(w) = \\frac{1}{2m} \\sum_{i=1}^m (f_{w}(x^{(i)}) - y^{(i)})^2$$  \n",
    "\n",
    "The goal:\n",
    "$$minimize\\ J(w)$$\n",
    "\n",
    "\n",
    "Suppose w = 0, \n",
    "\n",
    "That plots out the following regression line  \n",
    "\n",
    "![]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a966a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff327e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6e536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f467c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b89d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc03e97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877bc2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe3d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
